{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Juan Esteban Acosta López"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Parcial2JuanAcosta\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.200.129:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Parcial2JuanAcosta</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fe16449bdc0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "#[17 Ptos] Teniendo en cuenta el archivo departuredelays.csv aplique las siguientes transformaciones y acciones:\n",
    "rdd = spark.sparkContext.textFile(\"data/departuredelays.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[4 Ptos] Cree un RDD a partir de la carga del archivo departuredelays.csv. Divida cada línea por el carácter coma (,)\n",
    "split_rdd = rdd.map(lambda line: line.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registro 1:\n",
      "Date: date\n",
      "Delay: delay\n",
      "Distance: distance\n",
      "Origin: origin\n",
      "Destination: destination\n",
      "\n",
      "Registro 2:\n",
      "Date: 01011245\n",
      "Delay: 6\n",
      "Distance: 602\n",
      "Origin: ABE\n",
      "Destination: ATL\n",
      "\n",
      "Registro 3:\n",
      "Date: 01020600\n",
      "Delay: -8\n",
      "Distance: 369\n",
      "Origin: ABE\n",
      "Destination: DTW\n",
      "\n",
      "Registro 4:\n",
      "Date: 01021245\n",
      "Delay: -2\n",
      "Distance: 602\n",
      "Origin: ABE\n",
      "Destination: ATL\n",
      "\n",
      "Registro 5:\n",
      "Date: 01020605\n",
      "Delay: -4\n",
      "Distance: 602\n",
      "Origin: ABE\n",
      "Destination: ATL\n",
      "\n",
      "Registro 6:\n",
      "Date: 01031245\n",
      "Delay: -4\n",
      "Distance: 602\n",
      "Origin: ABE\n",
      "Destination: ATL\n",
      "\n",
      "Registro 7:\n",
      "Date: 01030605\n",
      "Delay: 0\n",
      "Distance: 602\n",
      "Origin: ABE\n",
      "Destination: ATL\n",
      "\n",
      "Registro 8:\n",
      "Date: 01041243\n",
      "Delay: 10\n",
      "Distance: 602\n",
      "Origin: ABE\n",
      "Destination: ATL\n",
      "\n",
      "Registro 9:\n",
      "Date: 01040605\n",
      "Delay: 28\n",
      "Distance: 602\n",
      "Origin: ABE\n",
      "Destination: ATL\n",
      "\n",
      "Registro 10:\n",
      "Date: 01051245\n",
      "Delay: 88\n",
      "Distance: 602\n",
      "Origin: ABE\n",
      "Destination: ATL\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#[2 Ptos] Imprima los diez primeros registros\n",
    "\n",
    "# Tomar los primeros diez registros\n",
    "first_10_records = split_rdd.take(10)\n",
    "\n",
    "# Imprimir los registros de manera más legible\n",
    "for i, record in enumerate(first_10_records, 1):\n",
    "    print(f\"Registro {i}:\")\n",
    "    print(f\"Date: {record[0]}\")\n",
    "    print(f\"Delay: {record[1]}\")\n",
    "    print(f\"Distance: {record[2]}\")\n",
    "    print(f\"Origin: {record[3]}\")\n",
    "    print(f\"Destination: {record[4]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: date, Distance: distance\n",
      "Date: 01011245, Distance: 602\n",
      "Date: 01020600, Distance: 369\n",
      "Date: 01021245, Distance: 602\n",
      "Date: 01020605, Distance: 602\n"
     ]
    }
   ],
   "source": [
    "#[3 Ptos] Imprima los cinco primeros registros correspondientes a los campos date y distance.\n",
    "# Selecciona los campos 'date' y 'distance' de los primeros cinco registros\n",
    "selected_data = split_rdd.map(lambda x: (x[0], x[2])).take(5)\n",
    "\n",
    "# Imprime los resultados\n",
    "for record in selected_data:\n",
    "    print(f\"Date: {record[0]}, Distance: {record[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origin: ABE, Destination: DTW\n",
      "Origin: ABE, Destination: DTW\n",
      "Origin: ABE, Destination: DTW\n",
      "Origin: ABE, Destination: DTW\n",
      "Origin: ABE, Destination: DTW\n"
     ]
    }
   ],
   "source": [
    "#[3 Ptos] Imprima los cinco primeros registros correspondientes a los campos origen y destination filtrados por el destino igual a DTW\n",
    "\n",
    "filtered_data = split_rdd.filter(lambda x: x[4] == 'DTW').map(lambda x: (x[3], x[4]))\n",
    "\n",
    "# Tomar los primeros cinco registros\n",
    "first_five_records = filtered_data.take(5)\n",
    "\n",
    "# Imprimir los resultados\n",
    "for record in first_five_records:\n",
    "    print(f\"Origin: {record[0]}, Destination: {record[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 32:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de minutos de retraso de SEA a SFO: 22293 minutos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#[5 Ptos] Obtenga el total de minutos de retraso de aquellos registros donde el origen sea igual a SEA y el destino sea igual a SFO\n",
    "\n",
    "# Filtrar los registros donde el origen es igual a 'SEA' y el destino es igual a 'SFO'\n",
    "filtered_data = split_rdd.filter(lambda x: x[3] == 'SEA' and x[4] == 'SFO')\n",
    "\n",
    "# Calcular el total de minutos de retraso\n",
    "total_delay_minutes = filtered_data.map(lambda x: int(x[1])).reduce(lambda x, y: x + y)\n",
    "\n",
    "print(f\"Total de minutos de retraso de SEA a SFO: {total_delay_minutes} minutos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "\n",
    "departures_df = spark.read.csv(\"data/departuredelays.csv\", header=True)\n",
    "departures_df.createOrReplaceTempView(\"departures\")\n",
    "\n",
    "airports_df = spark.read.option(\"delimiter\", \"\\t\").csv(\"data/airport-codes-na.txt\", header=True, inferSchema=True)\n",
    "airports_df.createOrReplaceTempView(\"airports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 37:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------+\n",
      "|State|DelayedFlights|\n",
      "+-----+--------------+\n",
      "|   WV|           248|\n",
      "|   VT|           257|\n",
      "|   ME|           388|\n",
      "|   WY|           565|\n",
      "|   NH|           598|\n",
      "|   ND|           765|\n",
      "|   SD|           770|\n",
      "|   KS|           808|\n",
      "|   MT|           933|\n",
      "|   RI|          1080|\n",
      "|   MS|          1130|\n",
      "|   ID|          1228|\n",
      "|   AK|          1642|\n",
      "|   IA|          1825|\n",
      "|   KY|          1837|\n",
      "|   NE|          1967|\n",
      "|   CT|          2015|\n",
      "|   AR|          2256|\n",
      "|   SC|          2286|\n",
      "|   NM|          2492|\n",
      "+-----+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#[10 Ptos] Teniendo en cuenta los archivos departuredelays.csv y airpot-codes-na.txt resolver la siguiente consulta: Listar los vuelos retrasados por estado y filtrados por el país USA. La lista debe estar ordenada por los vuelos retrasados en orden ascendente. Para la carga de los archivos tenga en cuenta lo siguiente: departuredelays.csv: Cree una vista temporal que incluya la cabecera airpot-codes-na.txt: Cree una vista temporal que incluya la cabecera, infiera el esquema y el separador de columnas sea \\t\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT a.State, COUNT(*) AS DelayedFlights\n",
    "FROM departures AS d\n",
    "JOIN airports AS a ON d.origin = a.IATA\n",
    "WHERE a.Country = 'USA' AND d.delay > 0\n",
    "GROUP BY a.State\n",
    "ORDER BY DelayedFlights ASC\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "\n",
    "result = spark.sql(query)\n",
    "\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+------+\n",
      "| id|weight|height|age|gender|\n",
      "+---+------+------+---+------+\n",
      "|  1| 144.5|   5.9| 33|     M|\n",
      "|  2| 167.2|   5.4| 45|     M|\n",
      "|  3| 124.1|   5.2| 23|     F|\n",
      "|  4| 144.5|   5.9| 33|     M|\n",
      "|  5| 133.2|   5.7| 54|     F|\n",
      "|  3| 124.1|   5.2| 23|     F|\n",
      "|  5| 129.2|   5.3| 42|     M|\n",
      "+---+------+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "#[23 Ptos] Con base en los datos de la tabla aplique las siguientes transformaciones y acciones:\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, LongType, DoubleType, StringType\n",
    "\n",
    "#[6 Ptos] Crear un DataFrame\n",
    "\n",
    "# Define los datos y las columnas\n",
    "data = [(1, 144.5, 5.9, 33, 'M'),\n",
    "        (2, 167.2, 5.4, 45, 'M'),\n",
    "        (3, 124.1, 5.2, 23, 'F'),\n",
    "        (4, 144.5, 5.9, 33, 'M'),\n",
    "        (5, 133.2, 5.7, 54, 'F'),\n",
    "        (3, 124.1, 5.2, 23, 'F'),\n",
    "        (5, 129.2, 5.3, 42, 'M')]\n",
    "\n",
    "columns = [\"id\", \"weight\", \"height\", \"age\", \"gender\"]\n",
    "\n",
    "# Define el esquema con los tipos de datos \n",
    "schema = StructType([\n",
    "    StructField(\"id\", LongType(), True),\n",
    "    StructField(\"weight\", DoubleType(), True),\n",
    "    StructField(\"height\", DoubleType(), True),\n",
    "    StructField(\"age\", LongType(), True),\n",
    "    StructField(\"gender\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Crea un DataFrame a partir de los datos y el esquema corregido\n",
    "df = spark.createDataFrame(data, schema=schema)\n",
    "\n",
    "# Muestra el DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- weight: double (nullable = true)\n",
      " |-- height: double (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#[3 Ptos] Imprimir el esquema del DataFrame\n",
    "\n",
    "# Imprimir el esquema del DataFrame\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad total de registros en el DataFrame es: 7\n"
     ]
    }
   ],
   "source": [
    "#[3 Ptos] Contar la cantidad total de registros\n",
    "\n",
    "# Contar la cantidad total de registros en el DataFrame\n",
    "total_records = df.count()\n",
    "\n",
    "print(f\"La cantidad total de registros en el DataFrame es: {total_records}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad total de registros sin duplicados es: 6\n"
     ]
    }
   ],
   "source": [
    "#[3 Ptos] Contar la cantidad total de registros sin duplicados\n",
    "\n",
    "# Eliminar registros duplicados y contar la cantidad total de registros únicos\n",
    "unique_records_count = df.distinct().count()\n",
    "\n",
    "print(f\"La cantidad total de registros sin duplicados es: {unique_records_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+------+\n",
      "| id|weight|height|age|gender|\n",
      "+---+------+------+---+------+\n",
      "|  3| 124.1|   5.2| 23|     F|\n",
      "|  3| 124.1|   5.2| 23|     F|\n",
      "+---+------+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#[4 Ptos] Imprimir aquellos registros donde el id sea igual a 3\n",
    "\n",
    "# Filtrar y mostrar registros donde \"id\" sea igual a 3\n",
    "filtered_df = df.filter(df[\"id\"] == 3)\n",
    "filtered_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "| id|gender|\n",
      "+---+------+\n",
      "|  1|     M|\n",
      "|  2|     M|\n",
      "|  4|     M|\n",
      "|  5|     F|\n",
      "|  5|     M|\n",
      "+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#[4 Ptos] Seleccionar los campos id y gender y filtrar por age mayor o igual a 30\n",
    "\n",
    "# Seleccionar los campos \"id\" y \"gender\" y filtrar por \"age\" mayor o igual a 30\n",
    "selected_df = df.select(\"id\", \"gender\").filter(df[\"age\"] >= 30)\n",
    "selected_df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
